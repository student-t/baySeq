%\VignetteIndexEntry{baySeq}
%\VignettePackage{baySeq}

\documentclass[a4paper]{article}

\title{baySeq: Empirical Bayesian analysis of patterns of differential expression in count data}
\author{Thomas J. Hardcastle}

\RequirePackage{/applications/R/R-3.2.4/library/BiocStyle/resources/tex/Bioconductor}

\AtBeginDocument{\bibliographystyle{/applications/R/R-3.2.4/library/BiocStyle/resources/tex/unsrturl}}
\usepackage{Sweave}
\begin{document}

\maketitle

\section{Introduction}

This vignette is intended to give a rapid introduction to the commands used in implementing empirical Bayesian methods of evaluating differential expression in high-throughput sequencing data by means of the \verb'baySeq' \textsf{R} package. For fuller details on the methods being used, consult Hardcastle \& Kelly (2010) \cite{hardcastle} and Hardcastle (2015) \cite{hardcastle2015}.

We assume that we have data from a set of sequencing or other high-throughput experiments, arranged in an array such that each column describes a sample and each row describes some genomic event for which data have been acquired. For example, the rows may correspond to the different sequences observed in a sequencing experiment. The data then consists of the number of times each sequence is observed in each sample. We wish to determine which, if any, rows of the data correspond to some patterns of differential expression across the samples. 

\verb'baySeq' uses empirical Bayesian methods to estimate the posterior likelihoods of each of a set of models that define patterns of differential expression for each row. This approach begins by considering a distribution for the row defined by a set of underlying parameters for which some prior distribution exists. By estimating this prior distribution from the data, we are able to assess, for a given model about the relatedness of our underlying parameters for multiple libraries, the posterior likelihood of the model.

In forming a set of models upon the data, we consider which patterns are biologically likely to occur in the data. For example, suppose we have count data from some organism in condition $A$ and condition $B$. Suppose further that we have two biological replicates for each condition, and hence four libraries $A_1, A_2, B_1, B_2$, where $A_1$, $A_2$ and $B_1$, $B_2$ are the replicates. It is reasonable to suppose that at least some of the rows may be unaffected by our experimental conditions $A$ and $B$, and the count data for each sample in these rows will be \textsl{equivalent}. These data need not in general be identical across each sample due to random effects and different library sizes, but they will share the same underlying parameters. However, some of the rows may be influenced by the different experimental conditions $A$ and $B$. The count data for the samples $A_1$ and $A_2$ will then be equivalent, as will the count data for the samples $B_1$ and $B_2$. However, the count data between samples $A_1, A_2, B_1, B_2$ will not be equivalent. For such a row, the data from samples $A_1$ and $A_2$ will then share the same set of underlying parameters, the data from samples $B_1$ and $B_2$ will share the same set of underlying parameters, but, crucially, the two sets will not be identical. However, \verb'baySeq' takes an alternative approach to analysis that allows more complicated patterns of differential expression than simple pairwise comparison, and thus is able to cope with more complex experimental designs (Section~\ref{sec:multgroup}).

In this initial vignette, we consider RNA-seq type data assumed to follow a negative binomial distribution. Alternative scenarios are discussed in the vignette \textsl{Advanced analysis using baySeq; generic distribution definitions}.

\section{Preparation}

We begin by loading the \verb'baySeq' package.



\begin{Schunk}
\begin{Sinput}
> library(baySeq)
\end{Sinput}
\end{Schunk}

Note that because the experiments that \verb'baySeq' is designed to analyse are usually massive, we should use (if possible) parallel processing as implemented by the \verb'snow' package. We use the \verb'parallel' package (if it exists), and define a \textsl{cluster}. If \verb'parallel' is not present, we can proceed anyway with a \verb'NULL' cluster. Results may be slightly different depending on whether or not a cluster is used owing to the non-deterministic elements of the method.
\begin{Schunk}
\begin{Sinput}
> if(require("parallel")) cl <- makeCluster(8) else cl <- NULL
\end{Sinput}
\end{Schunk}

We load a simulated data set consisting of count data on one thousand counts.

\begin{Schunk}
\begin{Sinput}
> data(simData)
> simData[1:10,]
\end{Sinput}
\begin{Soutput}
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    4    1    5    2    3    0    1    1    1     0
 [2,]    1    0    9    6    5    0    1    0    0     1
 [3,]    9    2    5    5   14    2    3    1    0     4
 [4,]    7    3    8    2    2    0    1    0    1     0
 [5,]    2    2    4    7    0    0    0    0    0     1
 [6,]    2    1    0    1    0    4    3    5    5     3
 [7,]    9    8    8    8    9    1    2    1    0     0
 [8,]    9    5    7    8    7    1    2    0    1     2
 [9,]    6    2    2    3    0    0    0    0    0     0
[10,]    1    0    2    0    1    3   17    2    2    10
\end{Soutput}
\end{Schunk}

The data are simulated such that the first hundred counts show differential expression between the first five libraries and the second five libraries. Our replicate structure, used to estimate the prior distributions on the data, can thus be defined as
\begin{Schunk}
\begin{Sinput}
>   replicates <- c("simA", "simA", "simA", "simA", "simA",
+                   "simB", "simB", "simB", "simB", "simB")
\end{Sinput}
\end{Schunk}

We can also establish two group structures for the data.

Each member (vector) contained within the 'groups' list corresponds to one model upon the data. In this setting, a model describes the patterns of data we expect to see at least some of the tags correspond to. In this simple example, we expect that some of the tags will be equivalently expressed between all ten libraries. This corresponds to the 'NDE' model, or vector \verb'c(1,1,1,1,1,1,1,1,1,1)' - all libraries belong to the same group for these tags. 

We also expect that some tags will show differential expression between the first five libraries and the second five libraries. For these tags, the two sets of libraries belong to different groups, and so we have the model 'DE', or vector \verb'c(1,1,1,1,1,2,2,2,2,2)' - the first five libraries belong to group 1 and the second five libraries to group 2. We thus have the following group structure

\begin{Schunk}
\begin{Sinput}
> groups <- list(NDE = c(1,1,1,1,1,1,1,1,1,1),
+                DE = c(1,1,1,1,1,2,2,2,2,2))
\end{Sinput}
\end{Schunk}

In a more complex experimental design (Section \ref{factorial}) we might have several additional models. The key to constructing vectors corresponding to a model is to see for which groups of libraries we expect equivalent expression of tags.

We note that the group for DE corresponds to the replicate structure. This will often be the case, but need not be in more complex experimental designs.

The ultimate aim of the \verb'baySeq' package is to evaluate posterior likelihoods of each model for each row of the data.

We begin by combining the count data and user-defined groups into a \verb'countData' object.

\begin{Schunk}
\begin{Sinput}
> CD <- new("countData", data = simData, replicates = replicates, groups = groups)
\end{Sinput}
\end{Schunk}

Library sizes can be inferred from the data if the user is not able to supply them.

\begin{Schunk}
\begin{Sinput}
>   libsizes(CD) <- getLibsizes(CD)
\end{Sinput}
\end{Schunk}

We can then plot the data in the form of an MA-plot, suitable modified to plot those data where the data are uniformly zero (and hence the log-ratio is infinite) (Figure~\ref{figMA}). Truly differentially expressed data can be identified in the plot by coloring these data red, while non-differentially expressed data are colored black.

\begin{Schunk}
\begin{Sinput}
> plotMA.CD(CD, samplesA = "simA", samplesB = "simB",
+           col = c(rep("red", 100), rep("black", 900)))
\end{Sinput}
\end{Schunk}

\begin{figure}[!ht]
\begin{center}
\includegraphics{baySeq-figPlotMA}
\caption{'MA'-plot for count data. Where the log-ratio would be infinite (because the data in one of the sample groups consists entirely of zeros, we plot instead the log-values of the other group. Truly differentially expressed data are colored red, and non-differentially expressed data black.}
\label{figMA}
\end{center}
\end{figure}


We can also optionally add annotation details into the \verb'@annotation' slot of the \verb'countData' object.

\begin{Schunk}
\begin{Sinput}
> CD@annotation <- data.frame(name = paste("count", 1:1000, sep = "_"))
\end{Sinput}
\end{Schunk}

\section{Negative-Binomial Approach}

We first estimate an empirical distribution on the parameters of the Negative Binomial distribution by bootstrapping from the data, taking individual counts and finding the quasi-likelihood parameters for a Negative Binomial distribution. By taking a sufficiently large sample, an empirical distribution on the parameters is estimated. A sample size of around 10000 iterations is suggested, depending on the data being used), but 1000 is used here to rapidly generate the plots and tables.

\begin{Schunk}
\begin{Sinput}
> CD <- getPriors.NB(CD, samplesize = 1000, estimation = "QL", cl = cl)
\end{Sinput}
\end{Schunk}

The calculated priors are stored in the \verb'@priors' slot of the \verb'countData' object produced as before. For the negative-binomial method, we are unable to form a conjugate prior distribution. Instead, we build an empirical prior distribution which we record in the list object \verb'$priors' of the slot \verb'@priors'. Each member of this list object corresponds to one of the models defined by the \verb'group' slot of the \verb'countData' object and contains the estimated parameters for each of the individual counts selected under the models. The vector \verb'$sampled' contained in the slot \verb'@priors' describes which rows were sampled to create these sets of parameters.

We then acquire posterior likelihoods, estimating the proportions of differentially expressed counts.

\begin{Schunk}
\begin{Sinput}
> CD <- getLikelihoods(CD, cl = cl, bootStraps = 3, verbose = FALSE)
\end{Sinput}
\begin{Soutput}
...
\end{Soutput}
\begin{Sinput}
> CD@estProps
\end{Sinput}
\begin{Soutput}
numeric(0)
\end{Soutput}
\begin{Sinput}
> CD@posteriors[1:10,]
\end{Sinput}
\begin{Soutput}
             NDE           DE
 [1,] -0.7182509 -0.668658236
 [2,] -1.1044953 -0.402536517
 [3,] -1.0081651 -0.453953780
 [4,] -2.8017825 -0.062622240
 [5,] -0.7890052 -0.605679477
 [6,] -1.0411667 -0.435474739
 [7,] -6.4331196 -0.001608722
 [8,] -4.4751954 -0.011453337
 [9,] -1.1732792 -0.370123308
[10,] -1.8065428 -0.179390934
\end{Soutput}
\begin{Sinput}
> CD@posteriors[101:110,]
\end{Sinput}
\begin{Soutput}
                NDE         DE
 [1,] -3.509570e-02  -3.367173
 [2,] -3.456222e-10 -21.785679
 [3,] -4.959439e-02  -3.028572
 [4,] -2.507815e-02  -3.698271
 [5,] -2.022689e-05 -10.808508
 [6,] -2.900704e-02  -3.554685
 [7,] -5.219352e-02  -2.978780
 [8,] -1.773987e-02  -4.040798
 [9,] -4.623394e-02  -3.097069
[10,] -1.502412e-02  -4.205601
\end{Soutput}
\end{Schunk}

Here the assumption of a Negative Binomial distribution with priors estimated by maximum likelihood gives an estimate of 
\begin{Schunk}
\begin{Soutput}
[1] NA
\end{Soutput}
\end{Schunk}
as the proportion of differential expressed counts in the simulated data, where in fact the proportion is known to be $0.1$.

\section{Results}

We can ask for the top candidates for differential expression using the \verb'topCounts' function.
\begin{Schunk}
\begin{Sinput}
> topCounts(CD, group = "DE")  
\end{Sinput}
\begin{Soutput}
   annotation simA.1 simA.2 simA.3 simA.4 simA.5 simB.1 simB.2 simB.3 simB.4 simB.5
1    count_80      1      1      0      1      1     13     21      8      6     20
2    count_78      1      1      0      1      1      8     13      7      9     10
3    count_66      0      0      0      0      0     15     10      4      4     10
4    count_21      2      0      1      1      0     15     15      6      5     11
5     count_7      9      8      8      8      9      1      2      1      0      0
6    count_26     13      4     11      5      7      1      1      1      0      0
7    count_64      6      6      8     11      9      1      1      0      0      1
8    count_72      0      0      1      0      0      7      6      4      3      8
9    count_83     14      6      9      2      9      1      0      0      1      1
10   count_27      5      3      6      4      7      0      0      0      1      0
   Likelihood ordering       FDR.DE      FWER.DE
1   0.9995791      2>1 0.0004208781 0.0004208781
2   0.9992829      2>1 0.0005689902 0.0011376785
3   0.9990943      2>1 0.0006812318 0.0020423631
4   0.9985733      2>1 0.0008675879 0.0034661055
5   0.9983926      1>2 0.0010155560 0.0050679624
6   0.9980266      1>2 0.0011752048 0.0070314101
7   0.9962283      1>2 0.0015461322 0.0107765864
8   0.9957691      2>1 0.0018817294 0.0149619013
9   0.9954451      1>2 0.0021787486 0.0194486539
10  0.9941751      1>2 0.0025433681 0.0251603097
\end{Soutput}
\end{Schunk}

We can plot the posterior likelihoods against the log-ratios of the two sets of samples using the \verb'plotPosteriors' function, coloring the truly differentially expressed data red and the non-differentially expressed data black (Figure~\ref{figPPs}).
\begin{Schunk}
\begin{Sinput}
> plotPosteriors(CD, group = "DE", col = c(rep("red", 100), rep("black", 900)))
\end{Sinput}
\end{Schunk}

\begin{figure}[!ht]
\begin{center}

\includegraphics{baySeq-figPlotPosteriors}
\caption{Posterior likelihoods of differential expression against log-ratio (where this would be non-infinite) or log values (where all data in the other sample group consists of zeros). Truly differentially expressed data are colored red, and non-differentially expressed data black.}
\label{figPPs}
\end{center}
\end{figure}


\clearpage

\section{Case Study: Analysis of sRNA-Seq Data}

\subsection{Introduction}

We will look at data sequenced from small RNAs acquired from six samples of root stock from \textsl{Arabidopsis thaliana} in a grafting experiment \cite{molnar}. Three different biological conditions exist within these data; one in which a Dicer 2,3,4 triple mutant shoot is grafted onto a Dicer 2,3,4 triple mutant root (\textbf{SL236} \& \textbf{SL260}), one in which a wild-type shoot is grafted onto a wild-type root (\textbf{SL239} \& \textbf{SL240}), and one in which a wild-type shoot is grafted onto a Dicer 2,3,4 triple mutant root (\textbf{SL237} \& \textbf{SL238}). Dicer 2,3,4 is required for the production of 22nt and 24nt small RNAs, as well as some 21nt ones. Consequently, if we detect differentially expressed  sRNA loci in the root stock of the grafts, we can make inferences about the mobility of small RNAs.

\subsection{Reading in data}

The data and annotation are stored in two text files. We can read them in using \textbf{R}'s standard functions.
\begin{Schunk}
\begin{Sinput}
> data(mobData)
> data(mobAnnotation)
\end{Sinput}
\end{Schunk}

\subsection{Making a countData object}

We can create a \verb'countData' object containing all the information we need for a first attempt at a differential expression analysis.

\subsubsection{Including lengths}

\label{Section::seglen}

If two genes are expressed at the same level, but one is twice the length of the other, then (on average) we will sequence twice as many reads from the longer gene. The same is true for sRNA loci, and so in these analyses it is often useful to include the lengths of each feature. The lengths can be derived from the annotation of each feature, but we need to explicitly declare them within the `countData' object.

\begin{Schunk}
\begin{Sinput}
> seglens <- mobAnnotation$end - mobAnnotation$start + 1
> cD <- new("countData", data = mobData, seglens = seglens, annotation = mobAnnotation)
\end{Sinput}
\end{Schunk}

Determining the best library scaling factor to use is a non-trivial task. The simplest approach would be to use the total number of sequenced reads aligning to the genome. However, this approach meas that a few sequences that appear at very high levels can drastically skew the size of the scaling factor. Bullard \textsl{et al} suggest that good results can be obtained by taking the sum of the reads below the $n$th percentile of the data.
\begin{Schunk}
\begin{Sinput}
> libsizes(cD) <- getLibsizes(cD, estimationType = "quantile")
\end{Sinput}
\end{Schunk}

\subsection{Pairwise Differential Expression}

We start by looking at a pairwise differential expression analysis between two of the sample types. The analysis between samples `SL236', `SL260' and `SL237', `SL238' should be a first step in discovering sRNA loci associated with mobility. 

We begin by selecting a subset of the available data:
\begin{Schunk}
\begin{Sinput}
> cDPair <- cD[,1:4]
\end{Sinput}
\end{Schunk}

We then need to define the replicate structure of the \verb'countData' object. We do this by creating a vector that defines the replicate group that each sample belongs to.
\begin{Schunk}
\begin{Sinput}
> replicates(cDPair) <- as.factor(c("D3/D3", "D3/D3", "WT/D3", "WT/D3"))
\end{Sinput}
\end{Schunk}

We next need to define each of the models applicable to the data. In the first case, it is reasonable to suppose that at least some of the loci will be unaffected by the different experimental conditions prevailing in our replicate groups, and so we create one model of no differential expression. 

We do this by defining a vector \verb'NDE'.
\begin{Schunk}
\begin{Sinput}
> NDE <- c(1,1,1,1)
\end{Sinput}
\end{Schunk}
Each member of the \verb'NDE' vector represents one sample in our experiment. By giving each item in the \verb'NDE' vector the same number, we indicate that, under the hypothesis of no differential expression, all the samples belong to the same group.

We may also conjecture that some of the loci will be affected depending on whether the shoot is a Dicer mutant or a wild-type \textsl{Arabidopsis} sample.
\begin{Schunk}
\begin{Sinput}
> mobile <- c("non-mobile","non-mobile","mobile","mobile")
\end{Sinput}
\end{Schunk}
This vector indicates that the third and fourth samples, which consist of the wild-type shoot samples, are in a separate expression group to the first and second samples, corresponding to the Dicer 2,3,4 mutant shoot.

We can now add these models to the locus data by modfiying the \verb'@groups' slot
\begin{Schunk}
\begin{Sinput}
> groups(cDPair) <- list(NDE = NDE, mobile = mobile)
\end{Sinput}
\end{Schunk}

Now that we have defined our models, we need to establish prior distributions for the data. We do this using the \verb'getPriors.NB' function.

\begin{Schunk}
\begin{Sinput}
> cDPair <- getPriors.NB(cDPair, samplesize = 1e4, cl = cl)
\end{Sinput}
\end{Schunk}


The accuracy of the distribution is determined by the number of data points used to estimate the distribution; the `samplesize'. Here we've used a small sample size to reduce the computational effort required, but higher values will give more accurate results (the default is 1e5).

Having found prior distributions for the data, we can identify posterior likelihoods for the data using the \verb'getLikelihoods' function. Before we do this, however, it is worth considering the possibility that some loci will not be expressed at all in our data.

\subsubsection{Null Data}

We first examine the priors to see if any `null' data, consisting of un-expressed sRNA loci, are present. If the distribution of priors for the non-differentially expressed group is bimodal, it is likely that some of the loci are expressed at substantially lower levels than others.
\begin{Schunk}
\begin{Sinput}
> plotNullPrior(cDPair)
\end{Sinput}
\end{Schunk}

There is some evidence for bimodality, with a small peak of lowly expressed data to the left of the distribution.

\begin{figure}[!ht]
\begin{center}
\includegraphics{baySeq-figPlotPriors}
\caption{Distribution of $\mu_{ij}$. Bimodality suggests the presence of `null', or un-expressed, data.}
\label{figMAPost}
\end{center}
\end{figure}

We can use the \verb'nullData = TRUE' option in the \verb'getLikelihoods' function to allow for the possibility that some of the loci are miscalled in our locus map, and should properly be identified as nulls.

\begin{Schunk}
\begin{Sinput}
> cDPair <- getLikelihoods(cDPair, nullData = TRUE, cl = cl)